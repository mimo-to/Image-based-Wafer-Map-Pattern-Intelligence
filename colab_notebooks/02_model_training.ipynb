{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup_title"
            },
            "source": [
                "# WaferScan AI: Phase 2 - Model Training\n",
                "\n",
                "This notebook covers loading the pre-split dataset, defining the ViT-Small model, and executing the training loop on Google Colab (Tesla T4)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsible_headings": false,
                "id": "cell-1-setup"
            },
            "outputs": [],
            "source": [
                "# CELL 1: Setup\n",
                "import os\n",
                "import sys\n",
                "import yaml\n",
                "import json\n",
                "import pickle\n",
                "import random\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import transforms\n",
                "from google.colab import drive\n",
                "import timm\n",
                "from tqdm import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.utils.class_weight import compute_class_weight\n",
                "\n",
                "# Mount Drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Deterministic behavior\n",
                "SEED = 42\n",
                "def set_seed(seed):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed_all(seed)\n",
                "        torch.backends.cudnn.deterministic = True\n",
                "        torch.backends.cudnn.benchmark = False\n",
                "\n",
                "set_seed(SEED)\n",
                "\n",
                "# Check GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "if device.type == 'cuda':\n",
                "    print(torch.cuda.get_device_name(0))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cell-2-config"
            },
            "outputs": [],
            "source": [
                "# CELL 2: Load Config\n",
                "PROJECT_ROOT = \"/content/drive/MyDrive/wafer-hackathon\"\n",
                "CONFIG_PATH = os.path.join(PROJECT_ROOT, \"configs/colab_training_config.yaml\")\n",
                "\n",
                "print(f\"Loading config from {CONFIG_PATH}...\")\n",
                "with open(CONFIG_PATH, 'r') as f:\n",
                "    config = yaml.safe_load(f)\n",
                "\n",
                "# Extract critical paths\n",
                "PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT, config['data']['processed_data'])\n",
                "CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, config['checkpoint']['checkpoint_path'])\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "\n",
                "print(\"Configuration loaded.\")\n",
                "\n",
                "# Sanity checks\n",
                "print(\"Processed data path:\", PROCESSED_DATA_PATH)\n",
                "print(\"Checkpoint directory:\", CHECKPOINT_DIR)\n",
                "print(\"Batch size:\", config['training']['batch_size'])\n",
                "print(\"Epochs:\", config['training']['epochs'])\n",
                "print(\"Backbone:\", config['model']['backbone'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cell-3-data"
            },
            "outputs": [],
            "source": [
                "# CELL 3: Load Data (No Re-splitting)\n",
                "print(f\"Loading dataset from {PROCESSED_DATA_PATH}...\")\n",
                "\n",
                "with open(PROCESSED_DATA_PATH, 'rb') as f:\n",
                "    dataset_pkl = pickle.load(f)\n",
                "\n",
                "all_images = dataset_pkl['images']\n",
                "all_labels = np.array(dataset_pkl['labels'])\n",
                "\n",
                "# CRITICAL: Use stored split indices\n",
                "train_idx = dataset_pkl['train_indices']\n",
                "val_idx = dataset_pkl['val_indices']\n",
                "test_idx = dataset_pkl['test_indices']\n",
                "\n",
                "print(\"Data loaded successfully.\")\n",
                "print(f\"Train size: {len(train_idx)}\")\n",
                "print(f\"Val size:   {len(val_idx)}\")\n",
                "print(f\"Test size:  {len(test_idx)}\")\n",
                "\n",
                "# Verify Train Class Distribution\n",
                "from collections import Counter\n",
                "train_dist = Counter(all_labels[train_idx])\n",
                "print(\"Train Distribution:\", dict(train_dist))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cell-4-dataset"
            },
            "outputs": [],
            "source": [
                "# CELL 4: Dataset Class\n",
                "class WaferDataset(Dataset):\n",
                "    def __init__(self, images, labels, indices, transform=None):\n",
                "        self.images = images\n",
                "        self.labels = labels\n",
                "        self.indices = indices\n",
                "        self.transform = transform\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.indices)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        real_idx = self.indices[idx]\n",
                "        img_array = self.images[real_idx]\n",
                "        label = self.labels[real_idx]\n",
                "\n",
                "        # Convert numpy array to PIL Image for torchvision transforms\n",
                "        # The raw images are (H, W).\n",
                "        # We simulate RGB by stacking 3 channels as required by ImageNet-pretrained ViT\n",
                "        \n",
                "        # Simple Manual Grayscale -> RGB (H, W) -> (H, W, 3)\n",
                "        img_rpc = np.stack([img_array]*3, axis=-1).astype(np.float32)\n",
                "        \n",
                "        # To PIL\n",
                "        img_pil = transforms.ToPILImage()(img_rpc)\n",
                "        \n",
                "        if self.transform:\n",
                "            img_tensor = self.transform(img_pil)\n",
                "        else:\n",
                "            img_tensor = transforms.ToTensor()(img_pil)\n",
                "            \n",
                "        return img_tensor, torch.tensor(label, dtype=torch.long)\n",
                "\n",
                "# Define Transforms\n",
                "img_size = 224\n",
                "mean = [0.485, 0.456, 0.406]\n",
                "std = [0.229, 0.224, 0.225]\n",
                "\n",
                "train_transform = transforms.Compose([\n",
                "    transforms.Resize((img_size, img_size)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomVerticalFlip(),\n",
                "    transforms.RandomRotation(15),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean, std)\n",
                "])\n",
                "\n",
                "val_transform = transforms.Compose([\n",
                "    transforms.Resize((img_size, img_size)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean, std)\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "07ad9e65",
            "metadata": {
                "id": "cell-4-5-dataset-split-sanity"
            },
            "outputs": [],
            "source": [
                "# CELL 4.5: Dataset Sanity Check\n",
                "sample_img, sample_label = WaferDataset(\n",
                "    all_images,\n",
                "    all_labels,\n",
                "    train_idx,\n",
                "    train_transform\n",
                ")[0]\n",
                "\n",
                "print(\"Sample Shape:\", sample_img.shape)\n",
                "print(\"Sample Range:\", sample_img.min().item(), sample_img.max().item())\n",
                "print(\"Label Type:\", sample_label.dtype)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "01672c9e",
            "metadata": {
                "id": "cell-5-dataloader"
            },
            "outputs": [],
            "source": [
                "# CELL 5: DataLoaders\n",
                "batch_size = config['training']['batch_size']\n",
                "\n",
                "train_set = WaferDataset(all_images, all_labels, train_idx, transform=train_transform)\n",
                "val_set = WaferDataset(all_images, all_labels, val_idx, transform=val_transform)\n",
                "\n",
                "# Shuffle train only\n",
                "train_loader = DataLoader(\n",
                "    train_set, \n",
                "    batch_size=batch_size, \n",
                "    shuffle=True, \n",
                "    num_workers=2, \n",
                "    pin_memory=True, \n",
                "    drop_last=True, \n",
                "    persistent_workers=True\n",
                ")\n",
                "\n",
                "val_loader = DataLoader(\n",
                "    val_set, \n",
                "    batch_size=batch_size, \n",
                "    shuffle=False, \n",
                "    num_workers=2, \n",
                "    pin_memory=True, \n",
                "    persistent_workers=True\n",
                ")\n",
                "\n",
                "print(f\"Train Batches: {len(train_loader)}\")\n",
                "print(f\"Val Batches: {len(val_loader)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "10df13c9",
            "metadata": {
                "id": "cell-5-5-dataloader-sanity"
            },
            "outputs": [],
            "source": [
                "# CELL 5.5: DataLoader Sanity Check\n",
                "images_batch, labels_batch = next(iter(train_loader))\n",
                "\n",
                "print(\"Images Batch:\", images_batch.shape)\n",
                "print(\"Labels Batch:\", labels_batch.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cell-6-model"
            },
            "outputs": [],
            "source": [
                "# CELL 6: Model Definition\n",
                "model_name = config['model']['backbone']\n",
                "num_classes = config['model']['num_classes']\n",
                "dropout_rate = config['model']['dropout']\n",
                "\n",
                "print(f\"Creating model: {model_name}\")\n",
                "\n",
                "# 1. Load backbone without classifier\n",
                "backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
                "\n",
                "# 2. Get feature dimension\n",
                "in_features = backbone.num_features\n",
                "\n",
                "# 3. Define classifier head\n",
                "classifier = nn.Sequential(\n",
                "    nn.Dropout(dropout_rate),\n",
                "    nn.Linear(in_features, num_classes)\n",
                ")\n",
                "\n",
                "# 4. Wrap into full model\n",
                "class WaferClassifier(nn.Module):\n",
                "    def __init__(self, backbone, classifier):\n",
                "        super().__init__()\n",
                "        self.backbone = backbone\n",
                "        self.classifier = classifier\n",
                "        \n",
                "    def forward(self, x):\n",
                "        features = self.backbone(x)\n",
                "        return self.classifier(features)\n",
                "\n",
                "model = WaferClassifier(backbone, classifier)\n",
                "model = model.to(device)\n",
                "\n",
                "param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"Trainable Parameters: {param_count:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cell-7-optimizer"
            },
            "outputs": [],
            "source": [
                "# CELL 7: Loss & Optimizer\n",
                "\n",
                "# Handle Imbalance using Class Weights\n",
                "if config['training']['use_class_weights']:\n",
                "    train_labels = all_labels[train_idx]\n",
                "    class_weights = compute_class_weight('balanced', classes=np.arange(num_classes), y=train_labels)\n",
                "    \n",
                "    # Normalize weights\n",
                "    class_weights = class_weights / class_weights.mean()\n",
                "    \n",
                "    class_weights_reg = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
                "    print(\"Class Weights enabled:\", class_weights_reg)\n",
                "else:\n",
                "    class_weights_reg = None\n",
                "\n",
                "# Loss function with optional label smoothing\n",
                "criterion = nn.CrossEntropyLoss(\n",
                "    weight=class_weights_reg, \n",
                "    label_smoothing=config['training'].get('label_smoothing', 0.0)\n",
                ")\n",
                "\n",
                "lr = config['training']['learning_rate']\n",
                "wd = config['training']['weight_decay']\n",
                "\n",
                "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
                "\n",
                "# Cosine Scheduler\n",
                "num_epochs = config['training']['epochs']\n",
                "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cell-8-training"
            },
            "outputs": [],
            "source": [
                "# CELL 8: Training Loop\n",
                "use_amp = config['training'].get('use_amp', False)\n",
                "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
                "\n",
                "best_acc = 0.0\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_top3_acc': []}\n",
                "checkpoint_every = config['checkpoint']['checkpoint_every']\n",
                "\n",
                "print(f\"Starting training (AMP={use_amp})...\")\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    # --- TRAIN ---\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
                "    for images, labels in loop:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            \n",
                "        if use_amp:\n",
                "            scaler.scale(loss).backward()\n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "        else:\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "        \n",
                "        running_loss += loss.item() * images.size(0)\n",
                "        _, predicted = outputs.max(1)\n",
                "        total += labels.size(0)\n",
                "        correct += predicted.eq(labels).sum().item()\n",
                "        \n",
                "        loop.set_postfix(loss=loss.item())\n",
                "        \n",
                "    epoch_loss = running_loss / total\n",
                "    epoch_acc = correct / total\n",
                "    \n",
                "    # --- VALIDATE ---\n",
                "    model.eval()\n",
                "    val_loss = 0.0\n",
                "    val_correct = 0\n",
                "    val_top3_correct = 0\n",
                "    val_total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            \n",
                "            val_loss += loss.item() * images.size(0)\n",
                "            _, predicted = outputs.max(1)\n",
                "            val_total += labels.size(0)\n",
                "            val_correct += predicted.eq(labels).sum().item()\n",
                "            \n",
                "            # Top-3\n",
                "            _, top3_preds = outputs.topk(3, dim=1)\n",
                "            val_top3_correct += top3_preds.eq(labels.view(-1, 1).expand_as(top3_preds)).sum().item()\n",
                "            \n",
                "    val_epoch_loss = val_loss / val_total\n",
                "    val_epoch_acc = val_correct / val_total\n",
                "    val_epoch_top3 = val_top3_correct / val_total\n",
                "    \n",
                "    # Update Schedule\n",
                "    scheduler.step()\n",
                "    \n",
                "    # Store History\n",
                "    history['train_loss'].append(epoch_loss)\n",
                "    history['train_acc'].append(epoch_acc)\n",
                "    history['val_loss'].append(val_epoch_loss)\n",
                "    history['val_acc'].append(val_epoch_acc)\n",
                "    history['val_top3_acc'].append(val_epoch_top3)\n",
                "    \n",
                "    print(f\"Results: Train Loss={epoch_loss:.4f}, Acc={epoch_acc:.4f} | Val Loss={val_epoch_loss:.4f}, Acc={val_epoch_acc:.4f}, Top3={val_epoch_top3:.4f}\")\n",
                "    \n",
                "    # Save Best Model\n",
                "    if val_epoch_acc > best_acc:\n",
                "        best_acc = val_epoch_acc\n",
                "        best_dir = os.path.dirname(os.path.join(PROJECT_ROOT, \"models/final/best_model.pth\"))\n",
                "        os.makedirs(best_dir, exist_ok=True)\n",
                "        best_path = os.path.join(PROJECT_ROOT, \"models/final/best_model.pth\")\n",
                "        torch.save(model.state_dict(), best_path)\n",
                "        print(f\"  New best model saved! ({best_acc:.4f})\")\n",
                "        \n",
                "    # Regular Checkpoint\n",
                "    if (epoch + 1) % checkpoint_every == 0:\n",
                "        ckpt_path = os.path.join(CHECKPOINT_DIR, f\"ckpt_epoch_{epoch+1}.pth\")\n",
                "        torch.save({\n",
                "            'epoch': epoch + 1,\n",
                "            'model_state_dict': model.state_dict(),\n",
                "            'optimizer_state_dict': optimizer.state_dict(),\n",
                "            'scheduler_state_dict': scheduler.state_dict(),\n",
                "            'loss': val_epoch_loss,\n",
                "        }, ckpt_path)\n",
                "        print(f\"  Checkpoint saved: {ckpt_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cell-9-plot"
            },
            "outputs": [],
            "source": [
                "# CELL 9: Plot Curves\n",
                "plot_dir = os.path.dirname(os.path.join(PROJECT_ROOT, \"models/metrics/training_curves.png\"))\n",
                "os.makedirs(plot_dir, exist_ok=True)\n",
                "\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "# Accuracy\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history['train_acc'], label='Train Acc')\n",
                "plt.plot(history['val_acc'], label='Val Acc')\n",
                "plt.title('Accuracy')\n",
                "plt.xlabel('Epoch')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "# Loss\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history['train_loss'], label='Train Loss')\n",
                "plt.plot(history['val_loss'], label='Val Loss')\n",
                "plt.title('Loss')\n",
                "plt.xlabel('Epoch')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plot_path = os.path.join(PROJECT_ROOT, \"models/metrics/training_curves.png\")\n",
                "plt.savefig(plot_path)\n",
                "print(f\"Curves saved to {plot_path}\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "cell-10-artifacts"
            },
            "outputs": [],
            "source": [
                "# CELL 10: Save Artifacts\n",
                "history_path = os.path.join(PROJECT_ROOT, \"models/metrics/training_history.json\")\n",
                "\n",
                "with open(history_path, 'w') as f:\n",
                "    json.dump(history, f)\n",
                "    \n",
                "final_model_path = os.path.join(PROJECT_ROOT, \"models/final/final_model.pth\")\n",
                "torch.save(model.state_dict(), final_model_path)\n",
                "\n",
                "print(\"Training Complete. Artifacts saved.\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
