{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cec58c8",
      "metadata": {
        "id": "1cec58c8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT = \"/content/drive/MyDrive/wafer-hackathon\"\n",
        "\n",
        "!mkdir -p $PROJECT_ROOT\n",
        "!mkdir -p $PROJECT_ROOT/data/raw\n",
        "!mkdir -p $PROJECT_ROOT/data/processed\n",
        "!mkdir -p $PROJECT_ROOT/models/checkpoints\n",
        "!mkdir -p $PROJECT_ROOT/models/final\n",
        "!mkdir -p $PROJECT_ROOT/models/onnx\n",
        "!mkdir -p $PROJECT_ROOT/models/metrics\n",
        "\n",
        "print(\"Drive project structure ready.\")\n"
      ],
      "metadata": {
        "id": "O0B6fHblaghJ"
      },
      "id": "O0B6fHblaghJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Dataset in Drive:\", os.path.exists(f\"{PROJECT_ROOT}/data/raw/LSWMD.pkl\"))\n"
      ],
      "metadata": {
        "id": "6gSGrViqKrVH"
      },
      "id": "6gSGrViqKrVH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install training extras (Colab has torch pre-installed)\n",
        "!pip install numpy==1.26.4\n",
        "!pip install timm==0.9.12\n",
        "!pip install netcal==1.3.5\n",
        "!pip install wandb==0.16.1\n",
        "\n",
        "# Verify\n",
        "import timm\n",
        "print(f\"timm version: {timm.__version__}\")"
      ],
      "metadata": {
        "id": "vaKwygXqbirH"
      },
      "id": "vaKwygXqbirH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==2.0.3\n",
        "import pandas as pd\n",
        "print(pd.__version__)\n",
        "\n"
      ],
      "metadata": {
        "id": "YopkC6V-kq4-"
      },
      "id": "YopkC6V-kq4-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Legacy pandas pickle support\n",
        "if \"pandas.indexes\" not in sys.modules:\n",
        "    sys.modules[\"pandas.indexes\"] = pd.core.indexes\n",
        "\n",
        "\n",
        "def load_wafer_dataset(\n",
        "    pkl_path: str,\n",
        ") -> Tuple[List[np.ndarray], List[int], pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load and validate WM-811K dataset from pickle file.\n",
        "\n",
        "    Args:\n",
        "        pkl_path: Path to LSWMD.pkl file\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (images, labels, metadata_df)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(pkl_path):\n",
        "        raise FileNotFoundError(f\"Dataset file not found: {pkl_path}\")\n",
        "\n",
        "    print(f\"Loading dataset from {pkl_path}...\")\n",
        "    try:\n",
        "        with open(pkl_path, \"rb\") as f:\n",
        "            data = pickle.load(f, encoding=\"latin1\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Failed to load pickle: {e}\")\n",
        "\n",
        "    # Define class mapping\n",
        "    class_map = {\n",
        "        \"none\": 0,\n",
        "        \"Center\": 1,\n",
        "        \"Donut\": 2,\n",
        "        \"Edge-Loc\": 3,\n",
        "        \"Edge-Ring\": 4,\n",
        "        \"Loc\": 5,\n",
        "        \"Near-full\": 6,\n",
        "        \"Random\": 7,\n",
        "        \"Scratch\": 8,\n",
        "    }\n",
        "\n",
        "    images: List[np.ndarray] = []\n",
        "    labels: List[int] = []\n",
        "    metadata_rows: List[Dict[str, Any]] = []\n",
        "\n",
        "    skipped_count = 0\n",
        "\n",
        "    # Optimize iteration for DataFrames\n",
        "    iterator = data\n",
        "    total = len(data)\n",
        "\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        iterator = data.itertuples()\n",
        "\n",
        "    for record in tqdm(iterator, total=total, desc=\"Processing wafers\"):\n",
        "        try:\n",
        "            # Extract fields from tuple or dict\n",
        "            if isinstance(record, tuple) and hasattr(record, \"waferMap\"):\n",
        "                wafer_map = record.waferMap\n",
        "                failure_type = record.failureType\n",
        "                lot_name = getattr(record, \"lotName\", \"\")\n",
        "                wafer_index = getattr(record, \"waferIndex\", 0)\n",
        "            elif isinstance(record, dict):\n",
        "                wafer_map = record.get(\"waferMap\")\n",
        "                failure_type = record.get(\"failureType\")\n",
        "                lot_name = record.get(\"lotName\", \"\")\n",
        "                wafer_index = record.get(\"waferIndex\", 0)\n",
        "            else:\n",
        "                wafer_map = getattr(record, \"waferMap\", None)\n",
        "                failure_type = getattr(record, \"failureType\", None)\n",
        "                lot_name = getattr(record, \"lotName\", \"\")\n",
        "                wafer_index = getattr(record, \"waferIndex\", 0)\n",
        "\n",
        "            # Skip invalid samples\n",
        "            if wafer_map is None or failure_type is None:\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            # Ensure 2D numpy array\n",
        "            wafer_map = np.array(wafer_map)\n",
        "\n",
        "            if wafer_map.ndim != 2:\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            # Normalize failureType format\n",
        "            if isinstance(failure_type, np.ndarray):\n",
        "                if failure_type.size == 0:\n",
        "                    f_label = \"none\"\n",
        "                else:\n",
        "                    item = failure_type.flat[0]\n",
        "                    f_label = str(item)\n",
        "            elif isinstance(failure_type, list):\n",
        "                if len(failure_type) == 0:\n",
        "                    f_label = \"none\"\n",
        "                else:\n",
        "                    item = failure_type[0]\n",
        "                    if isinstance(item, list) and len(item) > 0:\n",
        "                        f_label = str(item[0])\n",
        "                    else:\n",
        "                        f_label = str(item)\n",
        "            elif isinstance(failure_type, str):\n",
        "                f_label = failure_type\n",
        "            else:\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            f_label = f_label.strip()\n",
        "\n",
        "            # Map to integer label\n",
        "            if f_label not in class_map:\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            label_idx = class_map[f_label]\n",
        "\n",
        "            images.append(wafer_map)\n",
        "            labels.append(label_idx)\n",
        "            metadata_rows.append(\n",
        "                {\n",
        "                    \"lotName\": lot_name,\n",
        "                    \"waferIndex\": wafer_index,\n",
        "                    \"failureType\": f_label,\n",
        "                    \"mapped_label\": label_idx,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        except Exception:\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "    # Create DataFrame\n",
        "    metadata_df = pd.DataFrame(metadata_rows)\n",
        "\n",
        "    # Verify all classes exist\n",
        "    unique_labels = sorted(set(labels))\n",
        "    expected_classes = list(range(9))\n",
        "    if unique_labels != expected_classes:\n",
        "        missing = set(expected_classes) - set(unique_labels)\n",
        "        print(f\"WARNING: Datset missing classes: {missing}\")\n",
        "\n",
        "    # Calculate statistics\n",
        "    valid_count = len(images)\n",
        "\n",
        "    # Image dimensions\n",
        "    if valid_count > 0:\n",
        "        heights = [img.shape[0] for img in images]\n",
        "        widths = [img.shape[1] for img in images]\n",
        "        h_min, h_max = min(heights), max(heights)\n",
        "        w_min, w_max = min(widths), max(widths)\n",
        "    else:\n",
        "        h_min = h_max = w_min = w_max = 0\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Data Loading Complete: {valid_count} valid samples\")\n",
        "    print(f\"Skipped samples: {skipped_count}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"Class Distribution:\")\n",
        "\n",
        "    # Distribution\n",
        "    dist = Counter(labels)\n",
        "    # Reverse map for printing\n",
        "    inv_map = {v: k for k, v in class_map.items()}\n",
        "\n",
        "    for lbl, count in sorted(dist.items()):\n",
        "        name = inv_map.get(lbl, \"Unknown\")\n",
        "        pct = (count / valid_count) * 100 if valid_count > 0 else 0\n",
        "        print(f\"  {name} ({lbl}): {count} ({pct:.2f}%)\")\n",
        "\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Image Heights: Min={h_min}, Max={h_max}\")\n",
        "    print(f\"Image Widths:  Min={w_min}, Max={w_max}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    return images, labels, metadata_df\n"
      ],
      "metadata": {
        "id": "OCyE88I_kJ_i"
      },
      "id": "OCyE88I_kJ_i",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "images, labels, metadata = load_wafer_dataset(\n",
        "    '/content/drive/MyDrive/wafer-hackathon/data/raw/LSWMD.pkl'\n",
        ")\n",
        "\n",
        "print(\"Loaded:\", len(images))\n",
        "print(\"Metadata shape:\", metadata.shape)\n",
        "print(\"Unique labels:\", sorted(set(labels)))\n",
        "print(\"Label distribution:\", Counter(labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQyi4K1FkPjT",
        "outputId": "3ab09451-86ee-4141-f134-96d37bc1fe4f"
      },
      "id": "nQyi4K1FkPjT",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from /content/drive/MyDrive/wafer-hackathon/data/raw/LSWMD.pkl...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing wafers: 100%|██████████| 811457/811457 [00:03<00:00, 203976.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "Data Loading Complete: 811457 valid samples\n",
            "Skipped samples: 0\n",
            "----------------------------------------\n",
            "Class Distribution:\n",
            "  none (0): 785938 (96.86%)\n",
            "  Center (1): 4294 (0.53%)\n",
            "  Donut (2): 555 (0.07%)\n",
            "  Edge-Loc (3): 5189 (0.64%)\n",
            "  Edge-Ring (4): 9680 (1.19%)\n",
            "  Loc (5): 3593 (0.44%)\n",
            "  Near-full (6): 149 (0.02%)\n",
            "  Random (7): 866 (0.11%)\n",
            "  Scratch (8): 1193 (0.15%)\n",
            "----------------------------------------\n",
            "Image Heights: Min=6, Max=300\n",
            "Image Widths:  Min=3, Max=205\n",
            "----------------------------------------\n",
            "Loaded: 811457\n",
            "Metadata shape: (811457, 4)\n",
            "Unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "Label distribution: Counter({0: 785938, 4: 9680, 3: 5189, 1: 4294, 5: 3593, 8: 1193, 7: 866, 2: 555, 6: 149})\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}